# Hello, World!
Ol√° üëã equipe da DATUM!

Aqui √© o Thiago Farias ([Perfil LinkedIn](https://www.linkedin.com/in/fariasthiago/)), e estou empolgado em apresentar o meu teste t√©cnico para vaga de Engenheiro de Dados. Aqui est√° um guia detalhado sobre o projeto e suas funcionalidades.

## Conjunto de Dados
Para este projeto, escolhi o conjunto de dados do [Bike Store Relational Database](https://www.kaggle.com/datasets/dillonmyrick/bike-store-sample-database). O diagrama de Entidade e Relacionamento (ER) fornecido pode ser visto abaixo:

![Schema Bike Store](https://i.imgur.com/04YEup6.png)


## Camada Bronze

Nesta etapa, realizei a ingest√£o e prepara√ß√£o inicial dos dados do conjunto de dados do Kaggle. Abaixo est√° uma vis√£o geral das etapas realizadas nesta camada:

1. **Autentica√ß√£o Kaggle**: Autentiquei no Kaggle usando as credenciais fornecidas para acessar o conjunto de dados.
2. **Download e Armazenamento**: Baixei os arquivos do conjunto de dados do Kaggle e os armazenei no DBFS (Databricks File System) na camada bronze.
3. **Exporta√ß√£o para Delta Lake e Parquet**: Exportei os DataFrames para o formato Delta Lake e Parquet na camada bronze para facilitar o processamento e an√°lise posterior.

Essas etapas s√£o essenciais para preparar os dados para as pr√≥ximas etapas de transforma√ß√£o e an√°lise nas camadas subsequentes.

## Camada Silver

Na camada silver, realizei as seguintes transforma√ß√µes nos dados para prepar√°-los para an√°lises mais aprofundadas:

1. **Convers√£o de Valores 'NULL'**: Iterei sobre cada DataFrame para substituir valores 'NULL', tornando a representa√ß√£o dos valores nulos mais consistente e leg√≠vel.
2. **Verifica√ß√£o e Remo√ß√£o de Duplicatas**: Verifiquei e removi duplicatas em todos os DataFrames para garantir a integridade dos dados.
3. **Transforma√ß√µes Espec√≠ficas por DataFrame**:
   - **ORDERS**: Converti o campo "shipped_date" para o tipo Date e apliquei formata√ß√£o.
   - **STAFFS**: Converti o campo "manager_id" de string para integer e criei a coluna "full_name" concatenando "first_name" e "last_name".
   - **CUSTOMERS**: Criei a coluna "full_name" concatenando "first_name" e "last_name", e converti a coluna "zip_code" para string.
   - **STORES**: Converti a coluna "zip_code" para string.
4. **Exporta√ß√£o para Delta Lake e Parquet**: Exportei os DataFrames para os formatos Delta Lake e Parquet na camada silver.

Essas transforma√ß√µes s√£o fundamentais para limpar e preparar os dados para an√°lises posteriores na camada gold.

## Camada Gold

Na camada gold, realizei an√°lises avan√ßadas dos dados para extrair insights valiosos. Abaixo est√£o algumas das an√°lises e visualiza√ß√µes realizadas:

1. **Distribui√ß√£o de Receita por Loja**:
   - Consulta SQL para calcular a receita total por loja.
   - Gr√°fico de barras mostrando a distribui√ß√£o da receita por loja.

2. **Top 10 Clientes com Maior Gasto Total**:
   - Consulta SQL para identificar os 10 clientes que mais gastaram.
   - Gr√°fico de barras horizontais exibindo os 10 principais clientes com o maior gasto total.

3. **Distribui√ß√£o de Receita por Ano e por M√™s**:
   - Consultas SQL para calcular a receita total por ano e por m√™s.
   - Gr√°ficos de barras mostrando a distribui√ß√£o da receita ao longo do tempo, tanto por ano quanto por m√™s.

4. **Top 10 Produtos com Maior Receita Total**:
   - Consulta SQL para identificar os 10 produtos que geraram mais receita.
   - Gr√°fico de barras horizontais exibindo os 10 principais produtos com a maior receita total.

5. **Receita Total por Vendedor**:
   - Consulta SQL para calcular a receita total gerada por cada vendedor.
   - Gr√°fico de barras horizontais mostrando a receita total por vendedor.

6. **An√°lise RFV (Rec√™ncia, Frequ√™ncia, Valor)**:
   - Consulta SQL para segmentar os clientes com base na frequ√™ncia de compra, na rec√™ncia da √∫ltima compra e no valor gasto.
   - Gr√°ficos de contagem mostrando a distribui√ß√£o dos clientes em diferentes segmentos.

7. **M√©dia M√≥vel de 30 dias para Pedidos**:
   - Consulta SQL para calcular a m√©dia m√≥vel de 30 dias para o n√∫mero de pedidos.
   - Gr√°fico de linha mostrando a m√©dia m√≥vel de 30 dias para cada loja ao longo do tempo.

8. **M√©dia de Unidades Vendidas por M√™s do Ano, por Categoria de Produto**:
   - Consulta SQL para calcular a m√©dia de unidades vendidas por m√™s para cada categoria de produto.
   - Gr√°fico de barras mostrando a m√©dia de unidades vendidas por m√™s do ano para cada categoria de produto.

Essas an√°lises e visualiza√ß√µes fornecem uma compreens√£o mais profunda dos dados e podem orientar decis√µes estrat√©gicas para a empresa.


## SQL Data Warehouse
Carreguei os dados para tabelas permanentes no banco de dados BikeStore para facilitar o acesso e an√°lise por meio de consultas SQL e Power BI.

![DW](https://i.imgur.com/Hk6k6sA.png)

# Dashboards
- [Databricks](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1802048069101167/3500734898195404/2682982357215681/latest.html)
- [Power BI](https://app.powerbi.com/view?r=eyJrIjoiNTJlOGJkNmYtYTQ3OS00Mzc1LWJhYTEtM2Q0YTA1NmMzMWM5IiwidCI6ImFjYmJkZDFlLTE4YWYtNDIyMy04ZTdiLWMwZDk3MTllYTVmZiJ9&pageName=ReportSection)

![Dashboard](https://i.imgur.com/yjMC5Ax.png)

## Muito obrigado!

Agrade√ßo pela oportunidade de apresentar este teste t√©cnico e estou √† disposi√ß√£o para quaisquer esclarecimentos adicionais ou discuss√µes sobre o projeto. 